{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import warnings\n",
    "import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "from dataclasses import dataclass, field\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leonl\\OneDrive\\College\\Senior\\CSE 481DS\\Analysis\\classify\\gpt\\gpt_classify_fewshot.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/leonl/OneDrive/College/Senior/CSE%20481DS/Analysis/classify/gpt/gpt_classify_fewshot.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/leonl/OneDrive/College/Senior/CSE%20481DS/Analysis/classify/gpt/gpt_classify_fewshot.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtiktoken\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import embedding_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_PATH   = './trainset.csv'\n",
    "TO_LABEL_PATH        = './headlines.csv'\n",
    "OUT_PATH             = '../data/gpt_classified.csv'\n",
    "NUM_EXAMPLES         = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_version = '2024-06-01'\n",
    "openai.api_base = \"https://llm.leibmann.org/v1\"\n",
    "openai.api_key = \"keyzoned\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpful vLLM commands:\n",
    "- Start server: `python -m vllm.entrypoints.openai.api_server --model meta-llama/Meta-Llama-3-8B --dtype=half --download-dir /projects/bdata/llm_models/`\n",
    "- Base url: `http://localhost:8000/v1`\n",
    "- List models: `curl http://localhost:8000/v1/models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RETRIES          = 3\n",
    "MAX_TOKENS           = 300 # only include response; smaller helps with ratelimiting\n",
    "TEMPERATURE          = 0 # using 0 based on xinyi, down from 1.4 earlier\n",
    "RETRY_SECS           = 5\n",
    "PAUSE_SECS           = 1\n",
    "TIMEOUT_SECS         = 5\n",
    "LLM_DEPLOYMENT       = 'mistral-7b-instruct-v0.2' # 'gpt-4' or 'GPT-4o'. For vLLM use full path\n",
    "\n",
    "if 'localhost' in openai.api_base:\n",
    "    PROMPT_COST = 0 # dollars per 1,000 tokens\n",
    "    OUTPUT_COST = 0 # dollars per 1,000 tokens\n",
    "    \n",
    "# input from here https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/\n",
    "elif LLM_DEPLOYMENT == 'GPT-4o':\n",
    "    PROMPT_COST = 0.005 # dollars per 1,000 tokens\n",
    "    OUTPUT_COST = 0.015 # dollars per 1,000 tokens\n",
    "elif LLM_DEPLOYMENT == 'gpt-4':\n",
    "    PROMPT_COST = 0.03 # dollars per 1,000 tokens\n",
    "    OUTPUT_COST = 0.06 # dollars per 1,000 tokens\n",
    "else: raise ValueError(f\"Unknown LLM_DEPLOYMENT: {LLM_DEPLOYMENT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounting\n",
    "NUM_TOKENS_PROMPTED  = 0\n",
    "NUM_TOKENS_GENERATED = 0\n",
    "enc = tiktoken.encoding_for_model('gpt-4')\n",
    "def get_num_tokens(s):\n",
    "    return len( enc.encode(s) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Helpers for output parsing\n",
    "@dataclass\n",
    "class LLMCol:\n",
    "    \"\"\"Represents a single key-value pair in the dataframe. Used for easy parsing\"\"\"\n",
    "    key: str\n",
    "    allowed_values: set = field(default_factory=set)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.allowed_values = set(map(LLMCol.normalize_str, self.allowed_values))\n",
    "\n",
    "    def to_str(self, value:str):\n",
    "        value = LLMCol.normalize_str(value)\n",
    "        if len(self.allowed_values) > 0 and value not in self.allowed_values:\n",
    "            raise ValueError(f\"Malformed input: Value {value} not in allowed values {self.allowed_values}\")\n",
    "        return f\"{self.key}: {value}\"\n",
    "    \n",
    "    def parse_line(self, line:str) -> dict:\n",
    "        \"\"\"Parse a line of text into a key-value pair, performing the inverse of to_str\"\"\"\n",
    "        try:\n",
    "            k,v = re.split(r'\\W*:\\W*', line, maxsplit=1)\n",
    "            if len(self.allowed_values) > 0 and LLMCol.normalize_str(v) not in self.allowed_values:\n",
    "                raise ValueError(f\"Malformed output: value {v} not in allowed values {self.allowed_values}\")\n",
    "            if k.strip().casefold() != self.key.casefold():\n",
    "                raise ValueError(f\"Malformed output: key {k} does not match expected key {self.key}\")\n",
    "            \n",
    "            return {self.key: v}\n",
    "        except ValueError:\n",
    "            raise ValueError(f'Malformed output for line \"{line}\"')\n",
    "        \n",
    "    def parse_row(self, row:pd.Series|dict) -> str:\n",
    "        \"\"\"Parse a row of a dataframe into a string, performing the inverse of to_str\"\"\"\n",
    "        if isinstance(row, pd.Series):\n",
    "            if self.key not in row.index:\n",
    "                raise ValueError(f\"Key {self.key} not found in row\")\n",
    "            return self.to_str(row[self.key])\n",
    "        elif isinstance(row, dict):\n",
    "            if self.key not in row:\n",
    "                raise ValueError(f\"Key {self.key} not found in row\")\n",
    "            return self.to_str(row[self.key])\n",
    "        else:\n",
    "            raise ValueError(\"Expected a Series or dict\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def normalize_str(s:str) -> str:\n",
    "        return str(s).strip().casefold()\n",
    "    \n",
    "@dataclass\n",
    "class LLMSchema:\n",
    "    \"\"\"Represents a set of LLMRows, used for easy parsing\"\"\"\n",
    "    cols: list[LLMCol]\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.cols = tuple(self.cols)\n",
    "        \n",
    "        # Ensure no duplicate keys\n",
    "        keys_found = set()\n",
    "        for col in self.cols:\n",
    "            if col.key in keys_found:\n",
    "                raise ValueError(f\"Duplicate key: {col.key}\")\n",
    "            keys_found.add(col.key)\n",
    "    \n",
    "    @property\n",
    "    def keys(self):\n",
    "        return {c.key for c in self.cols}\n",
    "    \n",
    "    def parse_row(self, row:pd.Series|dict) -> str:\n",
    "        values = list()\n",
    "        for c in self.cols:\n",
    "            try:\n",
    "                values.append(c.parse_row(row))\n",
    "            except ValueError:\n",
    "                continue\n",
    "        return '\\n'.join(values)\n",
    "    \n",
    "    def parse_text(self, text:str) -> list[dict]:\n",
    "        \"\"\"Parse a text block into a dictionary of key-value pairs\"\"\"\n",
    "        output = list()\n",
    "        for block in text.split('\\n\\n'):\n",
    "            lines = re.split(r'(?<=\\n)(?=[^\\n]*:)', block)\n",
    "            pairs = dict()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                for col in self.cols:\n",
    "                    try:\n",
    "                        pairs.update(col.parse_line(line))\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            output.append(pairs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the LLM output\n",
    "schema = LLMSchema([\n",
    "    # LLMCol('subreddit'),\n",
    "    # LLMCol('rule'),\n",
    "    # LLMCol('rule_description'),\n",
    "    \n",
    "    LLMCol('breach mentioned', {'true', 'false'}),\n",
    "    LLMCol('company mentioned')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Prescriptive</th>\n",
       "      <th>Restrictive</th>\n",
       "      <th>Post Content</th>\n",
       "      <th>Post Format</th>\n",
       "      <th>User-Related</th>\n",
       "      <th>Not a Rule</th>\n",
       "      <th>Spam, Low Quality, Off-Topic, and Reposts</th>\n",
       "      <th>Post Tagging &amp; Flairing</th>\n",
       "      <th>Peer Engagement</th>\n",
       "      <th>Links &amp; External Content</th>\n",
       "      <th>Images</th>\n",
       "      <th>Commercialization</th>\n",
       "      <th>Illegal Content</th>\n",
       "      <th>Divisive Content</th>\n",
       "      <th>Respect for Others</th>\n",
       "      <th>Brigading</th>\n",
       "      <th>Ban Mentioned</th>\n",
       "      <th>Karma/Score Mentioned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th>rule</th>\n",
       "      <th>rule_description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>soccer</th>\n",
       "      <th>5. No Duplicates</th>\n",
       "      <th></th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <th>8. Extraneous Comic Book Movie submission</th>\n",
       "      <th></th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <th>1. 1. Age</th>\n",
       "      <th></th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      Prescriptive  \\\n",
       "subreddit rule                                      rule_description                 \n",
       "soccer    5. No Duplicates                                                   False   \n",
       "movies    8. Extraneous Comic Book Movie submission                          False   \n",
       "trees     1. 1. Age                                                          False   \n",
       "\n",
       "                                                                      Restrictive  \\\n",
       "subreddit rule                                      rule_description                \n",
       "soccer    5. No Duplicates                                                   True   \n",
       "movies    8. Extraneous Comic Book Movie submission                          True   \n",
       "trees     1. 1. Age                                                          True   \n",
       "\n",
       "                                                                      Post Content  \\\n",
       "subreddit rule                                      rule_description                 \n",
       "soccer    5. No Duplicates                                                    True   \n",
       "movies    8. Extraneous Comic Book Movie submission                           True   \n",
       "trees     1. 1. Age                                                          False   \n",
       "\n",
       "                                                                      Post Format  \\\n",
       "subreddit rule                                      rule_description                \n",
       "soccer    5. No Duplicates                                                  False   \n",
       "movies    8. Extraneous Comic Book Movie submission                         False   \n",
       "trees     1. 1. Age                                                         False   \n",
       "\n",
       "                                                                      User-Related  \\\n",
       "subreddit rule                                      rule_description                 \n",
       "soccer    5. No Duplicates                                                   False   \n",
       "movies    8. Extraneous Comic Book Movie submission                          False   \n",
       "trees     1. 1. Age                                                           True   \n",
       "\n",
       "                                                                      Not a Rule  \\\n",
       "subreddit rule                                      rule_description               \n",
       "soccer    5. No Duplicates                                                 False   \n",
       "movies    8. Extraneous Comic Book Movie submission                        False   \n",
       "trees     1. 1. Age                                                        False   \n",
       "\n",
       "                                                                      Spam, Low Quality, Off-Topic, and Reposts  \\\n",
       "subreddit rule                                      rule_description                                              \n",
       "soccer    5. No Duplicates                                                                                 True   \n",
       "movies    8. Extraneous Comic Book Movie submission                                                       False   \n",
       "trees     1. 1. Age                                                                                       False   \n",
       "\n",
       "                                                                      Post Tagging & Flairing  \\\n",
       "subreddit rule                                      rule_description                            \n",
       "soccer    5. No Duplicates                                                              False   \n",
       "movies    8. Extraneous Comic Book Movie submission                                     False   \n",
       "trees     1. 1. Age                                                                     False   \n",
       "\n",
       "                                                                      Peer Engagement  \\\n",
       "subreddit rule                                      rule_description                    \n",
       "soccer    5. No Duplicates                                                      False   \n",
       "movies    8. Extraneous Comic Book Movie submission                             False   \n",
       "trees     1. 1. Age                                                             False   \n",
       "\n",
       "                                                                      Links & External Content  \\\n",
       "subreddit rule                                      rule_description                             \n",
       "soccer    5. No Duplicates                                                               False   \n",
       "movies    8. Extraneous Comic Book Movie submission                                      False   \n",
       "trees     1. 1. Age                                                                      False   \n",
       "\n",
       "                                                                      Images  \\\n",
       "subreddit rule                                      rule_description           \n",
       "soccer    5. No Duplicates                                             False   \n",
       "movies    8. Extraneous Comic Book Movie submission                    False   \n",
       "trees     1. 1. Age                                                    False   \n",
       "\n",
       "                                                                      Commercialization  \\\n",
       "subreddit rule                                      rule_description                      \n",
       "soccer    5. No Duplicates                                                        False   \n",
       "movies    8. Extraneous Comic Book Movie submission                               False   \n",
       "trees     1. 1. Age                                                               False   \n",
       "\n",
       "                                                                      Illegal Content  \\\n",
       "subreddit rule                                      rule_description                    \n",
       "soccer    5. No Duplicates                                                      False   \n",
       "movies    8. Extraneous Comic Book Movie submission                             False   \n",
       "trees     1. 1. Age                                                             False   \n",
       "\n",
       "                                                                      Divisive Content  \\\n",
       "subreddit rule                                      rule_description                     \n",
       "soccer    5. No Duplicates                                                       False   \n",
       "movies    8. Extraneous Comic Book Movie submission                              False   \n",
       "trees     1. 1. Age                                                              False   \n",
       "\n",
       "                                                                      Respect for Others  \\\n",
       "subreddit rule                                      rule_description                       \n",
       "soccer    5. No Duplicates                                                         False   \n",
       "movies    8. Extraneous Comic Book Movie submission                                False   \n",
       "trees     1. 1. Age                                                                False   \n",
       "\n",
       "                                                                      Brigading  \\\n",
       "subreddit rule                                      rule_description              \n",
       "soccer    5. No Duplicates                                                False   \n",
       "movies    8. Extraneous Comic Book Movie submission                       False   \n",
       "trees     1. 1. Age                                                       False   \n",
       "\n",
       "                                                                      Ban Mentioned  \\\n",
       "subreddit rule                                      rule_description                  \n",
       "soccer    5. No Duplicates                                                    False   \n",
       "movies    8. Extraneous Comic Book Movie submission                           False   \n",
       "trees     1. 1. Age                                                           False   \n",
       "\n",
       "                                                                      Karma/Score Mentioned  \n",
       "subreddit rule                                      rule_description                         \n",
       "soccer    5. No Duplicates                                                            False  \n",
       "movies    8. Extraneous Comic Book Movie submission                                   False  \n",
       "trees     1. 1. Age                                                                   False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training set\n",
    "train_set = pd.read_csv(TRAINING_DATA_PATH)\n",
    "\n",
    "train_set['Headline'] = train_set['Headline'].apply(str.strip)\n",
    "train_set.set_index(['Date', 'Publication', 'Headline', 'URL'], inplace=True)\n",
    "for col in schema.cols:\n",
    "    if col.key in train_set.index.names:\n",
    "        continue\n",
    "    \n",
    "    if col.key not in train_set.columns:\n",
    "        print(f\"WARNING: Column {col.key} not found in training set but specified in schema\")\n",
    "        continue\n",
    "    \n",
    "    train_set[col.key] = train_set[col.key].apply(lambda x: len(str(x)) > 0 and str(x).lower() not in ['nan','false','0'])\n",
    "\n",
    "train_set.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct prompt\n",
    "from itertools import chain\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    '\\n'.join(f'{c} : {{{c}}}' for c in chain(train_set.index.names, train_set.columns)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = train_set.reset_index().astype(str).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for examples..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 66.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "print('Computing embeddings for examples...', end='')\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,       # This is the list[dict] of examples available to select from.\n",
    "    embedding_pipeline(),\n",
    "    # AzureOpenAIEmbeddings(\n",
    "    #     deployment = EMBEDDING_DEPLOYMENT\n",
    "    # ),              # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    Chroma,         # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    k=NUM_EXAMPLES  # This is the number of examples to produce.\n",
    ")\n",
    "print(f'done in {time.monotonic()-start_time:.1f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./prompt.txt') as f:\n",
    "    prompt_prefix = f.read()\n",
    "prompt_prefix += '\\n\\nYour answer should follow the format given in the examples:\\n'\n",
    "    \n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector = example_selector,\n",
    "    example_prompt   = example_prompt,\n",
    "    input_variables = list(train_set.index.names),\n",
    "    prefix           = prompt_prefix,\n",
    "    suffix           = '\\n'.join(chain((f'{c} : {{{c}}}' for c in train_set.index.names))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt formatting configured.\n",
      "Example prompt:\n",
      "Given a rule in a specific subreddit, identify topics and qualities about the rule.\n",
      "\n",
      "If the rule explicitly limits or forbids certain actions, mark it as \"Restrictive\".\n",
      "\n",
      "If a rule expresses general guidelines or desires for a community, mark it as \"Prescriptive\".\n",
      "\n",
      "If a rule explicitly states desired or undesired content within the subreddit, mark it as \"Post Content\".\n",
      "\n",
      "If a rule is related to users or would cause unequal enforcement if two different users posted the same content (including verification and prior approval rules), mark it as \"User-Related\".\n",
      "\n",
      "If a rule prescribes post structure, formatting, titling, or references a location to post (such as other subreddits or specific threads), mark it as \"Post Format\".\n",
      "\n",
      "If the content is sidebar information and not necessarily a rule, mark it as \"Not a Rule\".\n",
      "\n",
      "If a rule pertains to labeling/flairing, marking nsfw, using tags, etc., mark it as \"Post Tagging & Flairing\".\n",
      "\n",
      "If a rule encourages or discourages the quantity of on-site peer engagement, including reporting, commenting, voting, and general activity, mark it as \"Peer Engagement\".\n",
      "\n",
      "If a rule regulates large group actions, including raiding or mass-voting, mark it as \"Brigading\".\n",
      "\n",
      "If a rule is about links or the external, off-reddit content (excluding image content), mark it as \"Links & External Content\".\n",
      "\n",
      "If a rule pertains to the content or quality of images or videos, often including memes, mark it as \"Images\".\n",
      "\n",
      "If a rule regulates advertisement, self-promotion, referrals and referral links, or buying/selling, mark it as \"Commercialization\".\n",
      "\n",
      "If a rule explicitly mentions illegal content, including copyright infringement and piracy (but excluding harassment and hate speech), mark it as \"Illegal Content\".\n",
      "\n",
      "If a rule regulates content that is inherently divisive, such as politics, current events, or community-specific hot topics. , mark it as \"Divisive Content\". Only mark if the rule covers specific topics, i.e, the what being said, not how it was said.\n",
      "\n",
      "If a rule discourages hate speech, antagonization, harassment, or encourages respect for others (including swearing), mark it as \"Respect for Others\".\n",
      "\n",
      "If a rule covers low-quality, off-topic, spam, reposted, or otherwise generally-undesired content, mark it as \"Spam, Low Quality, Off-Topic, and Reposts\".\n",
      "\n",
      "If a rule explicitly mentions banning users, mark it as \"Ban Mentioned\".\n",
      "\n",
      "If a rule explicitly mentions karma or user scores, mark it as \"Karma/Score Mentioned\".\n",
      "\n",
      "Your answer should follow the format given in the examples:\n",
      "\n",
      "\n",
      "subreddit : AskReddit\n",
      "rule : 3. Rule 3 - Open ended questions only\n",
      "rule_description : \n",
      "Prescriptive : False\n",
      "Restrictive : True\n",
      "Post Content : False\n",
      "Post Format : True\n",
      "User-Related : False\n",
      "Not a Rule : False\n",
      "Spam, Low Quality, Off-Topic, and Reposts : False\n",
      "Post Tagging & Flairing : False\n",
      "Peer Engagement : False\n",
      "Links & External Content : False\n",
      "Images : False\n",
      "Commercialization : False\n",
      "Illegal Content : False\n",
      "Divisive Content : False\n",
      "Respect for Others : False\n",
      "Brigading : False\n",
      "Ban Mentioned : False\n",
      "Karma/Score Mentioned : False\n",
      "\n",
      "subreddit : AskReddit\n",
      "rule : 4. Rule 4 - No personal info\n",
      "rule_description : \n",
      "Prescriptive : False\n",
      "Restrictive : True\n",
      "Post Content : True\n",
      "Post Format : False\n",
      "User-Related : False\n",
      "Not a Rule : False\n",
      "Spam, Low Quality, Off-Topic, and Reposts : False\n",
      "Post Tagging & Flairing : False\n",
      "Peer Engagement : False\n",
      "Links & External Content : False\n",
      "Images : False\n",
      "Commercialization : False\n",
      "Illegal Content : False\n",
      "Divisive Content : False\n",
      "Respect for Others : False\n",
      "Brigading : False\n",
      "Ban Mentioned : False\n",
      "Karma/Score Mentioned : False\n",
      "\n",
      "subreddit : AskReddit\n",
      "rule : 4. Rule 4 - No personal info\n",
      "rule_description : \n",
      "Prescriptive : False\n",
      "Restrictive : True\n",
      "Post Content : True\n",
      "Post Format : False\n",
      "User-Related : False\n",
      "Not a Rule : False\n",
      "Spam, Low Quality, Off-Topic, and Reposts : False\n",
      "Post Tagging & Flairing : False\n",
      "Peer Engagement : False\n",
      "Links & External Content : False\n",
      "Images : False\n",
      "Commercialization : False\n",
      "Illegal Content : False\n",
      "Divisive Content : False\n",
      "Respect for Others : False\n",
      "Brigading : False\n",
      "Ban Mentioned : False\n",
      "Karma/Score Mentioned : False\n",
      "\n",
      "subreddit : IAmA\n",
      "rule : 1. All posts must contain proof\n",
      "rule_description : \n",
      "Prescriptive : True\n",
      "Restrictive : False\n",
      "Post Content : True\n",
      "Post Format : False\n",
      "User-Related : False\n",
      "Not a Rule : False\n",
      "Spam, Low Quality, Off-Topic, and Reposts : False\n",
      "Post Tagging & Flairing : False\n",
      "Peer Engagement : False\n",
      "Links & External Content : False\n",
      "Images : False\n",
      "Commercialization : False\n",
      "Illegal Content : False\n",
      "Divisive Content : False\n",
      "Respect for Others : False\n",
      "Brigading : False\n",
      "Ban Mentioned : False\n",
      "Karma/Score Mentioned : False\n",
      "\n",
      "subreddit : IAmA\n",
      "rule : 4. Top-level comments must ask a question\n",
      "rule_description : \n",
      "Prescriptive : True\n",
      "Restrictive : False\n",
      "Post Content : False\n",
      "Post Format : True\n",
      "User-Related : False\n",
      "Not a Rule : False\n",
      "Spam, Low Quality, Off-Topic, and Reposts : False\n",
      "Post Tagging & Flairing : False\n",
      "Peer Engagement : False\n",
      "Links & External Content : False\n",
      "Images : False\n",
      "Commercialization : False\n",
      "Illegal Content : False\n",
      "Divisive Content : False\n",
      "Respect for Others : False\n",
      "Brigading : False\n",
      "Ban Mentioned : False\n",
      "Karma/Score Mentioned : False\n",
      "\n",
      "subreddit : AskReddit\n",
      "rule : 6. Rule 6 - [Serious] tagged posts are off-limits to jokes or irrelevant replies\n",
      "rule_description : \n",
      "Prescriptive : False\n",
      "Restrictive : True\n",
      "Post Content : True\n",
      "Post Format : False\n",
      "User-Related : False\n",
      "Not a Rule : False\n",
      "Spam, Low Quality, Off-Topic, and Reposts : True\n",
      "Post Tagging & Flairing : True\n",
      "Peer Engagement : False\n",
      "Links & External Content : False\n",
      "Images : False\n",
      "Commercialization : False\n",
      "Illegal Content : False\n",
      "Divisive Content : False\n",
      "Respect for Others : False\n",
      "Brigading : False\n",
      "Ban Mentioned : False\n",
      "Karma/Score Mentioned : False\n",
      "\n",
      "subreddit : AskReddit\n",
      "rule : Please mark all posts with their content\n",
      "rule_description : \n"
     ]
    }
   ],
   "source": [
    "print('Prompt formatting configured.\\nExample prompt:')\n",
    "\n",
    "print(\n",
    "    prompt.format(\n",
    "        subreddit = 'AskReddit',\n",
    "        rule='Please mark all posts with their content',\n",
    "        rule_description=''\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(prompt):\n",
    "    current_tries = 1\n",
    "    \n",
    "    while current_tries <= MAX_RETRIES:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model         = LLM_DEPLOYMENT if 'localhost' in openai.api_base else None,\n",
    "                deployment_id = LLM_DEPLOYMENT if 'localhost' not in openai.api_base else None,\n",
    "                messages      = [{'role': 'user', 'content': prompt}],\n",
    "                max_tokens    = MAX_TOKENS,\n",
    "                temperature   = TEMPERATURE,\n",
    "            )\n",
    "            break\n",
    "        except openai.error.RateLimitError:\n",
    "            time.sleep(.1*4**current_tries)\n",
    "            current_tries += 1\n",
    "        except Exception as e:\n",
    "            if 'The response was filtered due to the prompt' in str(e):\n",
    "                raise RuntimeError('Prompt was filtered.')\n",
    "            \n",
    "            print('\\tError from OpenAI:', str(e))\n",
    "            print('\\tRetrying...')\n",
    "            time.sleep(RETRY_SECS)\n",
    "            current_tries += 1 \n",
    "    \n",
    "    if current_tries > MAX_RETRIES:\n",
    "        raise RuntimeError('No valid response from OpenAI.')\n",
    "    \n",
    "    global NUM_TOKENS_PROMPTED\n",
    "    global NUM_TOKENS_GENERATED\n",
    "    \n",
    "    NUM_TOKENS_PROMPTED  += get_num_tokens( prompt )\n",
    "    NUM_TOKENS_GENERATED += get_num_tokens( response['choices'][0]['message']['content'] )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000 rules to classify.\n"
     ]
    }
   ],
   "source": [
    "to_label = pd.read_csv(TO_LABEL_PATH)\n",
    "\n",
    "to_label['rule'] = to_label['rule'].apply(str.strip)  \n",
    "to_label['rule_description'] = to_label['rule_description'].apply(lambda x: str(x).strip() if str(x).lower() != 'nan' else '')\n",
    "\n",
    "to_label = to_label[~to_label.index.isin(train_set.index)] # Dedupe\n",
    "to_label.set_index(['subreddit','rule','rule_description'], inplace=True) # Match train set schema\n",
    "\n",
    "# Create columns to label\n",
    "for col in schema.cols:\n",
    "    if col.key in ['subreddit','rule','rule_description']:\n",
    "        continue\n",
    "    \n",
    "    if col.key not in to_label.columns:\n",
    "        to_label[col.key] = False\n",
    "\n",
    "# Assert that the schema of to_label and train_set match\n",
    "if not set(chain(train_set.index.names, train_set.columns)) <= set(chain(to_label.index.names, to_label.columns)):\n",
    "    raise ValueError(f'To Label schema does not match train set schema! \\n Missing Columns: {set(chain(train_set.index.names, train_set.columns)) - set(chain(to_label.index.names, to_label.columns))}')\n",
    "\n",
    "print(f'Loaded {len(to_label)} rules to classify.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1874/3000 [1:02:06<53:08,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys in response for ('dankmemes', \"15. Yes, we have a karma threshold. Don't ask us about it. This rule literally explains everything. So, to post here, your account needs to have: \\n\\n \\n existed for Some Time \\n 500 post karma \\n positive comment karma \\n \\n\\n Or, if you're a special enough snowflake who can produce original content, you can go to  r/specialsnowflake  and earn your way in a bit faster. \\n\\n Check your karma breakdown here:  http://old.reddit.com/u/me/overview \\n\\n Types of karma are explained here:  https://www.reddit.com/r/help/comments/au5t4i/post_karma_vs_comment_karma/eh5tgck/ \\n\\n You do not need more information. So don't ask.\", ''): {'Ban Mentioned', 'Karma/Score Mentioned'}\n",
      "Filling with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1889/3000 [1:02:49<1:07:57,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys in response for ('dankmemes', \"15. Yes, we have a karma threshold. Don't ask us about it. This rule literally explains everything. So, to post here, your account needs to have: \\n\\n \\n existed for Some Time \\n 1000 post + comment karma \\n positive comment karma \\n \\n\\n Or, if you're a special enough snowflake who can produce original content, you can go to  r/specialsnowflake  and bypass the threshold. \\n\\n Check your karma breakdown here:  http://old.reddit.com/u/me/overview \\n\\n Types of karma are explained here:  https://www.reddit.com/r/help/comments/au5t4i/post_karma_vs_comment_karma/eh5tgck/ \\n\\n You do not need more information. So don't ask.\", ''): {'Karma/Score Mentioned'}\n",
      "Filling with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 2679/3000 [1:28:31<09:56,  1.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Classifying ('wallstreetbets', '4. No Gay Shit or Being a Fag', ''):\n",
      "'content'\n",
      "  File \"/tmp/ipykernel_1484830/1342523222.py\", line 33, in query\n",
      "Missing keys in response for ('wallstreetbets', '4. No Gay Shit or Being a Fag', ''): {'Images', 'Not a Rule', 'Links & External Content', 'Spam, Low Quality, Off-Topic, and Reposts', 'Restrictive', 'Karma/Score Mentioned', 'Peer Engagement', 'Illegal Content', 'Respect for Others', 'Brigading', 'Post Content', 'User-Related', 'Post Format', 'Ban Mentioned', 'Commercialization', 'Divisive Content', 'Prescriptive', 'Post Tagging & Flairing'}\n",
      "Filling with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 2816/3000 [1:33:11<05:58,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Classifying ('Animemes', '12. No lewd Loli/Shota content', ''):\n",
      "'content'\n",
      "  File \"/tmp/ipykernel_1484830/1342523222.py\", line 33, in query\n",
      "Missing keys in response for ('Animemes', '12. No lewd Loli/Shota content', ''): {'Images', 'Not a Rule', 'Links & External Content', 'Spam, Low Quality, Off-Topic, and Reposts', 'Restrictive', 'Karma/Score Mentioned', 'Peer Engagement', 'Illegal Content', 'Respect for Others', 'Brigading', 'Post Content', 'User-Related', 'Post Format', 'Ban Mentioned', 'Commercialization', 'Divisive Content', 'Prescriptive', 'Post Tagging & Flairing'}\n",
      "Filling with NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [1:39:14<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.monotonic()\n",
    "\n",
    "to_bool = lambda x: len(str(x)) > 0 and str(x).lower() not in ['nan','false','0']\n",
    "\n",
    "for idx, row in tqdm(list(to_label.iterrows())):\n",
    "    prompt_args = dict(zip(to_label.index.names, idx))\n",
    "    prompt_str = prompt.format(**prompt_args) # format prompt with row index\n",
    "    parsed_response = dict()\n",
    "    \n",
    "    try:\n",
    "        response = query(prompt_str)\n",
    "        \n",
    "        response_str = response['choices'][0]['message']['content']\n",
    "        response_str = response_str.replace(prompt_str, '').strip()\n",
    "        response_str = \"Prescriptive : \" + response_str if not ':' in response_str.splitlines()[0] else response_str\n",
    "        response_str = response_str[response_str.find('Prescriptive : '):]\n",
    "        \n",
    "        parsed_response = schema.parse_text(response_str)[0]\n",
    "        \n",
    "        # Drop all keys in parsed_response that are not in schema\n",
    "        for k in list(parsed_response.keys()):\n",
    "            if k not in schema.keys:\n",
    "                del parsed_response[k]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error Classifying {idx}:\\n{e}\")\n",
    "        \n",
    "        # Find line number of error\n",
    "        print(next((line for line in reversed(traceback.format_exc().split('\\n')) if re.search(r'line \\d+', line)), 'Unknown'))\n",
    "        \n",
    "    # Fill all missing fields with NaN\n",
    "    if not set(schema.keys) <= set(parsed_response.keys()):\n",
    "        print(f\"Missing keys in response for {idx}: {set(schema.keys) - set(parsed_response.keys())}\")\n",
    "        print('Filling with NaN')\n",
    "        for k in schema.keys:\n",
    "            if k not in parsed_response:\n",
    "                parsed_response[k] = np.nan\n",
    "    \n",
    "    # Fill in the row with the parsed response\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for k,v in parsed_response.items():\n",
    "            to_label.loc[idx,k] = to_bool(v)\n",
    "    to_label.to_csv(OUT_PATH)\n",
    "    \n",
    "elapsed_time = time.monotonic() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_response = schema.parse_text(response_str)[0]\n",
    "        \n",
    "# Drop all keys in parsed_response that are not in schema\n",
    "for k in list(parsed_response.keys()):\n",
    "    if k not in schema.keys:\n",
    "        del parsed_response[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prescriptive : False\\nRestrictive : True\\nPost Content : False\\nPost Format : False\\nUser-Related : False\\nNot a Rule : False\\nSpam, Low Quality, Off-Topic, and Reposts : False\\nPost Tagging & Flairing : False\\nPeer Engagement : True\\nLinks & External Content : False\\nImages : False\\nCommercialization : False\\nIllegal Content : False\\nDivisive Content : False\\nRespect for Others : False\\nBrigading : False\\nBan Mentioned : False\\nKarma/Score Mentioned : True'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3,000 records in 99.2 minutes.\n",
      "4,432,262 tokens prompted, 434,489 generated.\n",
      "Total run cost ~ $28.68\n"
     ]
    }
   ],
   "source": [
    "print(f'Processed {len(to_label):,d} records in {elapsed_time/60:.1f} minutes.')\n",
    "\n",
    "print(f'{NUM_TOKENS_PROMPTED:,d} tokens prompted, {NUM_TOKENS_GENERATED:,d} generated.')\n",
    "\n",
    "run_cost = (NUM_TOKENS_PROMPTED/1000 * PROMPT_COST)+(NUM_TOKENS_GENERATED/1000 * OUTPUT_COST)\n",
    "\n",
    "print(f'Total run cost ~ ${run_cost:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../cost_tracking.jsonl', 'a') as f:\n",
    "    costs = {\n",
    "        'date'                  : datetime.date.today().isoformat(),\n",
    "        'time'                  : datetime.datetime.now().strftime('%H:%M'),\n",
    "        'tokens_prompted'       : NUM_TOKENS_PROMPTED,\n",
    "        'tokens_generated'      : NUM_TOKENS_GENERATED,\n",
    "        'run_cost_usd'          : run_cost,\n",
    "        'elapsed_seconds'       : elapsed_time,\n",
    "        'records_processed'     : len(to_label),\n",
    "    }\n",
    "    \n",
    "    f.write(json.dumps(costs)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
