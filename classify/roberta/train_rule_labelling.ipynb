{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:38:15.790945Z",
     "iopub.status.busy": "2024-06-24T18:38:15.790550Z",
     "iopub.status.idle": "2024-06-24T18:38:41.256921Z",
     "shell.execute_reply": "2024-06-24T18:38:41.256207Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "import warnings\n",
    "\n",
    "np.random.seed(0)\n",
    "to_bool = lambda x: len(str(x)) > 0 and str(x).lower() not in ['nan','false','0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules Classification\n",
    "\n",
    "Classify rules according to paper\n",
    "\n",
    "Tutorial Used: [RoBERTa Classification](https://jesusleal.io/2020/10/20/RoBERTA-Text-Classification/)\n",
    "\n",
    "- [] TODO: find the paper that classifies the rules\n",
    "- [] TODO: find the paper that mentions best general hyperparameters for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:38:41.260128Z",
     "iopub.status.busy": "2024-06-24T18:38:41.259399Z",
     "iopub.status.idle": "2024-06-24T18:38:41.506257Z",
     "shell.execute_reply": "2024-06-24T18:38:41.505379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1352386/632706310.py:7: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  all_data[cols] = all_data[cols].applymap(to_bool)\n"
     ]
    }
   ],
   "source": [
    "cols = ['Prescriptive', 'Restrictive', 'Post Content', 'Post Format', 'User-Related', 'Not a Rule', 'Spam, Low Quality, Off-Topic, and Reposts', 'Post Tagging & Flairing', 'Peer Engagement', 'Links & External Content', 'Images', 'Commercialization', 'Illegal Content', 'Divisive Content', 'Respect for Others', 'Brigading', 'Ban Mentioned', 'Karma/Score Mentioned']\n",
    "\n",
    "all_data = pd.read_csv('./data_400_human/all_data.csv')\n",
    "all_data = all_data[all_data['rule'].notna() & all_data['rule'].apply(lambda x: type(x) == str and len(x.strip()) > 0)]\n",
    "\n",
    "# Convert the dataset to correct types\n",
    "all_data[cols] = all_data[cols].applymap(to_bool)\n",
    "all_data['subreddit'] = all_data['subreddit'].astype(str)\n",
    "all_data['rule'] = all_data['rule'].astype(str)\n",
    "all_data['labels'] = all_data.apply(lambda row: [float(row[col]) for col in cols], axis=1)\n",
    "\n",
    "# Drop duplicate columns if in csv\n",
    "for dcol in ['subreddit.1', 'rule.1', 'rule_description.1']:\n",
    "    if dcol in all_data.columns:\n",
    "        all_data.drop(dcol, axis=1, inplace=True)\n",
    "\n",
    "train = all_data.sample(frac=0.8, random_state=0)\n",
    "train.to_csv('./data_400_human/train.csv', index=False)\n",
    "\n",
    "test = all_data.drop(train.index)\n",
    "test.to_csv('./data_400_human/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 240, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data), len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:38:41.508896Z",
     "iopub.status.busy": "2024-06-24T18:38:41.508514Z",
     "iopub.status.idle": "2024-06-24T18:38:41.603249Z",
     "shell.execute_reply": "2024-06-24T18:38:41.602647Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train)\n",
    "test_data = Dataset.from_pandas(test)\n",
    "\n",
    "# Remove from_pandas artifacts\n",
    "train_data = train_data.remove_columns(\"__index_level_0__\")\n",
    "test_data = test_data.remove_columns(\"__index_level_0__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:38:41.605908Z",
     "iopub.status.busy": "2024-06-24T18:38:41.605523Z",
     "iopub.status.idle": "2024-06-24T18:38:41.611121Z",
     "shell.execute_reply": "2024-06-24T18:38:41.610598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['subreddit', 'rule', 'rule_description', 'Prescriptive', 'Restrictive', 'Post Content', 'Post Format', 'User-Related', 'Not a Rule', 'Spam, Low Quality, Off-Topic, and Reposts', 'Post Tagging & Flairing', 'Peer Engagement', 'Links & External Content', 'Images', 'Commercialization', 'Illegal Content', 'Divisive Content', 'Respect for Others', 'Brigading', 'Ban Mentioned', 'Karma/Score Mentioned', 'labels'],\n",
       "    num_rows: 240\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:38:41.643299Z",
     "iopub.status.busy": "2024-06-24T18:38:41.642958Z",
     "iopub.status.idle": "2024-06-24T18:38:47.528271Z",
     "shell.execute_reply": "2024-06-24T18:38:47.527755Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(train_data['labels'][0])\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', problem_type=\"multi_label_classification\")\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels, id2label={str(i): label for i, label in enumerate(cols)}, label2id={label: i for i, label in enumerate(cols)})\n",
    "\n",
    "def tokenize_data(data):\n",
    "    tokenized_data = tokenizer(data['rule'], padding=True, truncation=True, return_tensors='pt')\n",
    "    tokenized_data['labels'] = torch.tensor(data['labels'])\n",
    "    return Dataset.from_dict(tokenized_data)\n",
    "\n",
    "train_data = tokenize_data(train_data)\n",
    "test_data = tokenize_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:38:47.530716Z",
     "iopub.status.busy": "2024-06-24T18:38:47.530407Z",
     "iopub.status.idle": "2024-06-24T18:38:47.959297Z",
     "shell.execute_reply": "2024-06-24T18:38:47.958732Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/projects/bdata/reddit_rules_classification/models',          # output directory\n",
    "    num_train_epochs=10,             # total number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    warmup_steps=113,                # number of warmup steps for learning rate scheduler. 6% of total steps\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='/projects/bdata/reddit_rules_classification/models/logs',            # directory for storing logs\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "def compute_metrics(pred) -> dict:\n",
    "    # computes accuracy, f1, and loss for multilabel classification\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    \n",
    "    pred_labels = np.where(preds > 0.5, 1, 0)\n",
    "    acc = accuracy_score(labels, pred_labels)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, pred_labels, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'support': support,\n",
    "    }\n",
    "    \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:38:47.961755Z",
     "iopub.status.busy": "2024-06-24T18:38:47.961383Z",
     "iopub.status.idle": "2024-06-24T18:38:57.416454Z",
     "shell.execute_reply": "2024-06-24T18:38:57.415858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:38:57.418902Z",
     "iopub.status.busy": "2024-06-24T18:38:57.418373Z",
     "iopub.status.idle": "2024-06-24T18:53:33.755317Z",
     "shell.execute_reply": "2024-06-24T18:53:33.754754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 01:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.669880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.491465</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.426502</td>\n",
       "      <td>0.426680</td>\n",
       "      <td>0.432584</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353371</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.465584</td>\n",
       "      <td>0.418352</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.309238</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.465584</td>\n",
       "      <td>0.418352</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279462</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.472758</td>\n",
       "      <td>0.443956</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254212</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.547586</td>\n",
       "      <td>0.564859</td>\n",
       "      <td>0.544944</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240125</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.547954</td>\n",
       "      <td>0.575304</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.230906</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.581556</td>\n",
       "      <td>0.636537</td>\n",
       "      <td>0.578652</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.216816</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.615815</td>\n",
       "      <td>0.655948</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212695</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.631518</td>\n",
       "      <td>0.762133</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:53:33.757603Z",
     "iopub.status.busy": "2024-06-24T18:53:33.757240Z",
     "iopub.status.idle": "2024-06-24T18:53:41.921681Z",
     "shell.execute_reply": "2024-06-24T18:53:41.921117Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.21269512176513672,\n",
       " 'eval_accuracy': 0.21666666666666667,\n",
       " 'eval_f1': 0.6315184113164831,\n",
       " 'eval_precision': 0.7621326539500043,\n",
       " 'eval_recall': 0.5955056179775281,\n",
       " 'eval_support': None,\n",
       " 'eval_runtime': 0.7888,\n",
       " 'eval_samples_per_second': 76.06,\n",
       " 'eval_steps_per_second': 5.071,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:53:41.924375Z",
     "iopub.status.busy": "2024-06-24T18:53:41.923858Z",
     "iopub.status.idle": "2024-06-24T18:53:55.931858Z",
     "shell.execute_reply": "2024-06-24T18:53:55.931255Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/homes/gws/lleibm/miniconda3/envs/hf2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "\n",
    "import json\n",
    "with open('/projects/bdata/reddit_rules_classification/models/train_log.json', 'w') as f:\n",
    "    f.write(json.dumps({\n",
    "        'train': [x for x in trainer.state.log_history if 'loss' in x],\n",
    "        'eval': [x for x in trainer.state.log_history if 'eval_loss' in x],\n",
    "        'final': trainer.evaluate(),\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-24T18:53:55.933904Z",
     "iopub.status.busy": "2024-06-24T18:53:55.933538Z",
     "iopub.status.idle": "2024-06-24T18:53:55.939247Z",
     "shell.execute_reply": "2024-06-24T18:53:55.938733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eval_loss': 0.6698799729347229,\n",
       "  'eval_accuracy': 0.0,\n",
       "  'eval_f1': 0.0,\n",
       "  'eval_precision': 0.0,\n",
       "  'eval_recall': 0.0,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.793,\n",
       "  'eval_samples_per_second': 75.659,\n",
       "  'eval_steps_per_second': 5.044,\n",
       "  'epoch': 1.0,\n",
       "  'step': 15},\n",
       " {'eval_loss': 0.49146509170532227,\n",
       "  'eval_accuracy': 0.05,\n",
       "  'eval_f1': 0.4265016473768692,\n",
       "  'eval_precision': 0.426679885437321,\n",
       "  'eval_recall': 0.43258426966292135,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7893,\n",
       "  'eval_samples_per_second': 76.019,\n",
       "  'eval_steps_per_second': 5.068,\n",
       "  'epoch': 2.0,\n",
       "  'step': 30},\n",
       " {'eval_loss': 0.3533714711666107,\n",
       "  'eval_accuracy': 0.06666666666666667,\n",
       "  'eval_f1': 0.46558398640355014,\n",
       "  'eval_precision': 0.41835205992509367,\n",
       "  'eval_recall': 0.5280898876404494,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7877,\n",
       "  'eval_samples_per_second': 76.174,\n",
       "  'eval_steps_per_second': 5.078,\n",
       "  'epoch': 3.0,\n",
       "  'step': 45},\n",
       " {'eval_loss': 0.30923786759376526,\n",
       "  'eval_accuracy': 0.06666666666666667,\n",
       "  'eval_f1': 0.46558398640355014,\n",
       "  'eval_precision': 0.41835205992509367,\n",
       "  'eval_recall': 0.5280898876404494,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7878,\n",
       "  'eval_samples_per_second': 76.163,\n",
       "  'eval_steps_per_second': 5.078,\n",
       "  'epoch': 4.0,\n",
       "  'step': 60},\n",
       " {'eval_loss': 0.2794623374938965,\n",
       "  'eval_accuracy': 0.06666666666666667,\n",
       "  'eval_f1': 0.47275776868000075,\n",
       "  'eval_precision': 0.44395569368077137,\n",
       "  'eval_recall': 0.5056179775280899,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7859,\n",
       "  'eval_samples_per_second': 76.347,\n",
       "  'eval_steps_per_second': 5.09,\n",
       "  'epoch': 5.0,\n",
       "  'step': 75},\n",
       " {'eval_loss': 0.25421208143234253,\n",
       "  'eval_accuracy': 0.08333333333333333,\n",
       "  'eval_f1': 0.5475860679429747,\n",
       "  'eval_precision': 0.5648587106648252,\n",
       "  'eval_recall': 0.5449438202247191,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7888,\n",
       "  'eval_samples_per_second': 76.061,\n",
       "  'eval_steps_per_second': 5.071,\n",
       "  'epoch': 6.0,\n",
       "  'step': 90},\n",
       " {'eval_loss': 0.24012483656406403,\n",
       "  'eval_accuracy': 0.06666666666666667,\n",
       "  'eval_f1': 0.5479539231422906,\n",
       "  'eval_precision': 0.575304257627226,\n",
       "  'eval_recall': 0.5280898876404494,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7871,\n",
       "  'eval_samples_per_second': 76.225,\n",
       "  'eval_steps_per_second': 5.082,\n",
       "  'epoch': 7.0,\n",
       "  'step': 105},\n",
       " {'eval_loss': 0.23090599477291107,\n",
       "  'eval_accuracy': 0.18333333333333332,\n",
       "  'eval_f1': 0.5815563878485226,\n",
       "  'eval_precision': 0.6365369181380417,\n",
       "  'eval_recall': 0.5786516853932584,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7881,\n",
       "  'eval_samples_per_second': 76.13,\n",
       "  'eval_steps_per_second': 5.075,\n",
       "  'epoch': 8.0,\n",
       "  'step': 120},\n",
       " {'eval_loss': 0.21681614220142365,\n",
       "  'eval_accuracy': 0.2,\n",
       "  'eval_f1': 0.6158151566973039,\n",
       "  'eval_precision': 0.6559477601050635,\n",
       "  'eval_recall': 0.5955056179775281,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7875,\n",
       "  'eval_samples_per_second': 76.189,\n",
       "  'eval_steps_per_second': 5.079,\n",
       "  'epoch': 9.0,\n",
       "  'step': 135},\n",
       " {'eval_loss': 0.21269512176513672,\n",
       "  'eval_accuracy': 0.21666666666666667,\n",
       "  'eval_f1': 0.6315184113164831,\n",
       "  'eval_precision': 0.7621326539500043,\n",
       "  'eval_recall': 0.5955056179775281,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7855,\n",
       "  'eval_samples_per_second': 76.388,\n",
       "  'eval_steps_per_second': 5.093,\n",
       "  'epoch': 10.0,\n",
       "  'step': 150},\n",
       " {'train_runtime': 90.1378,\n",
       "  'train_samples_per_second': 26.626,\n",
       "  'train_steps_per_second': 1.664,\n",
       "  'total_flos': 164056863196800.0,\n",
       "  'train_loss': 0.35654220581054685,\n",
       "  'epoch': 10.0,\n",
       "  'step': 150},\n",
       " {'eval_loss': 0.21269512176513672,\n",
       "  'eval_accuracy': 0.21666666666666667,\n",
       "  'eval_f1': 0.6315184113164831,\n",
       "  'eval_precision': 0.7621326539500043,\n",
       "  'eval_recall': 0.5955056179775281,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7888,\n",
       "  'eval_samples_per_second': 76.06,\n",
       "  'eval_steps_per_second': 5.071,\n",
       "  'epoch': 10.0,\n",
       "  'step': 150},\n",
       " {'eval_loss': 0.21269512176513672,\n",
       "  'eval_accuracy': 0.21666666666666667,\n",
       "  'eval_f1': 0.6315184113164831,\n",
       "  'eval_precision': 0.7621326539500043,\n",
       "  'eval_recall': 0.5955056179775281,\n",
       "  'eval_support': None,\n",
       "  'eval_runtime': 0.7815,\n",
       "  'eval_samples_per_second': 76.775,\n",
       "  'eval_steps_per_second': 5.118,\n",
       "  'epoch': 10.0,\n",
       "  'step': 150}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline_classify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
