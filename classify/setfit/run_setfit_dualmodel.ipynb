{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from setfit import SetFitModel\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "breach_model  = SetFitModel._from_pretrained('./classify/setfit/model_breach')\n",
    "company_model = SetFitModel._from_pretrained('./classify/setfit/model_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leonl\\OneDrive\\College\\Senior\\CSE 481DS\\Analysis\\classify\\setfit\\run_setfit.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/leonl/OneDrive/College/Senior/CSE%20481DS/Analysis/classify/setfit/run_setfit.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run model on headlines!\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/leonl/OneDrive/College/Senior/CSE%20481DS/Analysis/classify/setfit/run_setfit.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m./data/headlines.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/leonl/OneDrive/College/Senior/CSE%20481DS/Analysis/classify/setfit/run_setfit.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m preds \u001b[39m=\u001b[39m saved_model\u001b[39m.\u001b[39;49mpredict(df[\u001b[39m'\u001b[39;49m\u001b[39mHeadline\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m# on cpu :(\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/transformers/lib/python3.11/site-packages/setfit/modeling.py:559\u001b[0m, in \u001b[0;36mSetFitModel.predict\u001b[0;34m(self, inputs, batch_size, as_numpy, use_labels, show_progress_bar)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m is_singular:\n\u001b[1;32m    558\u001b[0m     inputs \u001b[39m=\u001b[39m [inputs]\n\u001b[0;32m--> 559\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(inputs, batch_size\u001b[39m=\u001b[39;49mbatch_size, show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar)\n\u001b[1;32m    560\u001b[0m preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_head\u001b[39m.\u001b[39mpredict(embeddings)\n\u001b[1;32m    561\u001b[0m \u001b[39m# If labels are defined, we don't have multilabels & the output is not already strings, then we convert to string labels\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/transformers/lib/python3.11/site-packages/setfit/modeling.py:451\u001b[0m, in \u001b[0;36mSetFitModel.encode\u001b[0;34m(self, inputs, batch_size, show_progress_bar)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\n\u001b[1;32m    437\u001b[0m     \u001b[39mself\u001b[39m, inputs: List[\u001b[39mstr\u001b[39m], batch_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m, show_progress_bar: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    438\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[torch\u001b[39m.\u001b[39mTensor, np\u001b[39m.\u001b[39mndarray]:\n\u001b[1;32m    439\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert input sentences to embeddings using the `SentenceTransformer` body.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m        torch Tensor if this model has a differentiable Torch head, or otherwise as a numpy array.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_body\u001b[39m.\u001b[39;49mencode(\n\u001b[1;32m    452\u001b[0m         inputs,\n\u001b[1;32m    453\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    454\u001b[0m         normalize_embeddings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_embeddings,\n\u001b[1;32m    455\u001b[0m         convert_to_tensor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhas_differentiable_head,\n\u001b[1;32m    456\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    457\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/transformers/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:589\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[39mfor\u001b[39;00m start_index \u001b[39min\u001b[39;00m trange(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(sentences), batch_size, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatches\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    588\u001b[0m     sentences_batch \u001b[39m=\u001b[39m sentences_sorted[start_index : start_index \u001b[39m+\u001b[39m batch_size]\n\u001b[0;32m--> 589\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(sentences_batch)\n\u001b[1;32m    590\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhpu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    591\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features:\n",
      "File \u001b[0;32m~/miniforge3/envs/transformers/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:1044\u001b[0m, in \u001b[0;36mSentenceTransformer.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39mself\u001b[39m, texts: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mdict\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mtuple\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Tensor]:\n\u001b[1;32m   1034\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    Tokenizes the texts.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[39m            \"attention_mask\", and \"token_type_ids\".\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1044\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_first_module()\u001b[39m.\u001b[39;49mtokenize(texts)\n",
      "File \u001b[0;32m~/miniforge3/envs/transformers/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:386\u001b[0m, in \u001b[0;36mTransformer.tokenize\u001b[0;34m(self, texts, padding)\u001b[0m\n\u001b[1;32m    384\u001b[0m batch1, batch2 \u001b[39m=\u001b[39m [], []\n\u001b[1;32m    385\u001b[0m \u001b[39mfor\u001b[39;00m text_tuple \u001b[39min\u001b[39;00m texts:\n\u001b[0;32m--> 386\u001b[0m     batch1\u001b[39m.\u001b[39mappend(text_tuple[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    387\u001b[0m     batch2\u001b[39m.\u001b[39mappend(text_tuple[\u001b[39m1\u001b[39m])\n\u001b[1;32m    388\u001b[0m to_tokenize \u001b[39m=\u001b[39m [batch1, batch2]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Run model on headlines!\n",
    "df = pd.read_csv(\"./data/headlines.csv\").dropna(subset=['Headline'])\n",
    "\n",
    "pred_breach  = breach_model.predict(df['Headline']) # on cpu :(\n",
    "pred_company = company_model.predict(df['Headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to a csv file\n",
    "preds = pd.DataFrame({'BreachMentioned': [bool(p) for p in pred_breach], 'CompanyMenioned': [bool(p) for p in pred_company]})\n",
    "df = pd.concat([df, preds], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/setfit_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
